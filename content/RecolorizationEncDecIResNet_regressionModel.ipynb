{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27384,
     "status": "ok",
     "timestamp": 1604867914231,
     "user": {
      "displayName": "A. Irgendwie",
      "photoUrl": "",
      "userId": "06901651170485627471"
     },
     "user_tz": -60
    },
    "id": "IZ5E4mhEIW6E",
    "outputId": "66619ceb-3782-4d35-bda7-ca31d219a828"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from google.colab import drive\\ndrive.mount('/content/drive/')\\n\\nsave_path = '/content/drive/My Drive/RecolorizationEncDecIResNet/output/\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################\n",
    "# use google drive, only for Colab\n",
    "##############################################################\n",
    "'''from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "save_path = '/content/drive/My Drive/RecolorizationEncDecIResNet/output/'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 184490,
     "status": "ok",
     "timestamp": 1604868102871,
     "user": {
      "displayName": "A. Irgendwie",
      "photoUrl": "",
      "userId": "06901651170485627471"
     },
     "user_tz": -60
    },
    "id": "i5e5dpwi6Ztw",
    "outputId": "11fee8af-00d3-4e5a-fb4e-f67e7716781f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!cp /content/drive/My\\\\ Drive/RecolorizationEncDecIResNet.zip /content/\\n!unzip RecolorizationEncDecIResNet.zip -d ./'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy code from google drive and unzip\n",
    "'''!cp /content/drive/My\\ Drive/RecolorizationEncDecIResNet.zip /content/\n",
    "!unzip RecolorizationEncDecIResNet.zip -d ./'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2989,
     "status": "ok",
     "timestamp": 1604868523553,
     "user": {
      "displayName": "A. Irgendwie",
      "photoUrl": "",
      "userId": "06901651170485627471"
     },
     "user_tz": -60
    },
    "id": "oprM4HcJlbDD"
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# import packages\n",
    "##############################################################\n",
    "import numpy as np\n",
    "import itertools\n",
    "import shutil\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tensorflow/keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger,ReduceLROnPlateau\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, InputLayer, BatchNormalization\n",
    "#from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPool2D, UpSampling2D\n",
    "#from tensorflow.keras.layers import RepeatVector, Permute, Input, Reshape, concatenate\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop \n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from skimage.io import imsave\n",
    "from skimage import img_as_ubyte\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from PIL import Image, ImageOps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1343,
     "status": "ok",
     "timestamp": 1604868540550,
     "user": {
      "displayName": "A. Irgendwie",
      "photoUrl": "",
      "userId": "06901651170485627471"
     },
     "user_tz": -60
    },
    "id": "6RjpN4qvmgIV",
    "outputId": "97d8b361-4144-4401-9881-9691f4af6334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d91482\\Desktop\\code\\finalVersion\\content/RecolorizationEncDecIResNet\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# set variables / global parameters\n",
    "##############################################################\n",
    "# number of training/validation/test examples\n",
    "num_train_images = 1 #40000 # 9000\n",
    "num_valid_images = 1 #5148 # 1815\n",
    "num_test_images = 1\n",
    "\n",
    "# learning parameter\n",
    "var_learning_rate = 0.0001\n",
    "var_batch_size = 1\n",
    "var_num_show_image = 1\n",
    "var_epochs=1\n",
    "var_steps_per_epoch=int(num_train_images / var_batch_size * var_num_show_image)\n",
    "var_steps_validation = int(num_valid_images / var_batch_size)\n",
    "var_verbose=1\n",
    "\n",
    "# select data read mode\n",
    "# 0: import/read data to/from array (use for <10GB), 1: import/read data to/from drive (use for >10GB)\n",
    "read_mode = 1\n",
    "\n",
    "# select running mode (train, proceed training or inference)\n",
    "# 0: train model, 1: proceed with training (use saved model), 2: inference on test data (use saved model)\n",
    "run_mode = 0\n",
    "# use only for run_mode = 1 or 2\n",
    "if(run_mode==1 or run_mode==2):\n",
    "  model_to_proceed = 'modelEncDecIResNet001.h5'\n",
    "  var_initial_epoch = 1\n",
    "\n",
    "# select running environment\n",
    "working_path = os.getcwd()\n",
    "working_path+='/RecolorizationEncDecIResNet'\n",
    "print(working_path)\n",
    "\n",
    "# datasets\n",
    "# 0: unsplash photos, 1: movie posters\n",
    "var_data_set = 1\n",
    "if(var_data_set == 0):\n",
    "  train_dataset = 'unsplash/train/'\n",
    "  valid_dataset = 'unsplash/valid/'\n",
    "  test_dataset = 'unsplash/test/'\n",
    "elif(var_data_set == 1):\n",
    "  train_dataset = 'postersLargeClearedResizedPadded/train/'\n",
    "  valid_dataset = 'postersLargeClearedResizedPadded/valid/'\n",
    "  test_dataset = 'postersLargeClearedResizedPadded/test/'\n",
    "elif(var_data_set == 2):\n",
    "  train_dataset = 'postersLargeMixedResizedPadded/train/'\n",
    "  valid_dataset = 'postersLargeMixedResizedPadded/valid/'\n",
    "  test_dataset = 'postersLargeMixedResizedPadded/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12292,
     "status": "ok",
     "timestamp": 1604868556553,
     "user": {
      "displayName": "A. Irgendwie",
      "photoUrl": "",
      "userId": "06901651170485627471"
     },
     "user_tz": -60
    },
    "id": "RrBQeeeSmpws",
    "outputId": "4c2b499d-2ea9-46d5-c558-973df1d56b3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaible GPUs:  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 6285759322486631837,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 6995561419278732335\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 16317065246848437849\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################\n",
    "# set/test cpu/gpu settings\n",
    "# activate memory growth on gpu\n",
    "##############################################################\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print('Avaible GPUs: ', len(physical_devices))\n",
    "if(len(physical_devices) > 0):\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0],True)\n",
    "device_lib.list_local_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1545,
     "status": "ok",
     "timestamp": 1604868562515,
     "user": {
      "displayName": "A. Irgendwie",
      "photoUrl": "",
      "userId": "06901651170485627471"
     },
     "user_tz": -60
    },
    "id": "pOIZXm72m4q0"
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# change to working directory\n",
    "# prepare paths for train / valid / test images\n",
    "# import utils / custom functions\n",
    "##############################################################\n",
    "if os.getcwd() != working_path:\n",
    "  os.chdir(working_path)\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# set paths to subfolders\n",
    "train_path = current_path + '/input/' + train_dataset\n",
    "valid_path = current_path + '/input/' + valid_dataset\n",
    "test_path = current_path + '/input/' + test_dataset\n",
    "output_path = current_path + '/output/'\n",
    "logs_path = current_path + '/logs/'\n",
    "\n",
    "# import custom utils with auxiliary functions\n",
    "import sys\n",
    "sys.path.append(current_path + '/code/')\n",
    "import utils\n",
    "from utils import plotImages, inception_embedding, batch_generator, evaluate_input, import_images, image_resize_with_padding, metric_psnr\n",
    "import modelEncDecIResNet \n",
    "from modelEncDecIResNet import get_modelEncDecIResNet, LossAndErrorPrintingCallback, CustomTensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "executionInfo": {
     "elapsed": 1685,
     "status": "ok",
     "timestamp": 1604868568601,
     "user": {
      "displayName": "A. Irgendwie",
      "photoUrl": "",
      "userId": "06901651170485627471"
     },
     "user_tz": -60
    },
    "id": "Dmu9YGJFnqA1",
    "outputId": "622dcdcf-496a-41a5-e288-03d70e770d14"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##############################################################\n",
    "# import data and plot 10 examples\n",
    "# optional, when reading data from drive\n",
    "##############################################################\n",
    "Xtrain_rgb = []\n",
    "Xvalid_rgb = []\n",
    "Xtest_rgb = []\n",
    "\n",
    "# import data as images or from .npy-files \n",
    "if(read_mode==0):\n",
    "  # import validation data\n",
    "  Xbuffer = import_images(valid_path + 'images/', num_valid_images)\n",
    "  Xvalid_rgb = np.array(Xbuffer[0:num_valid_images], dtype=float) / 255\n",
    "  #Xvalid_rgb = np.load(valid_path + 'validArray.npy')\n",
    "  print('validation data imported')\n",
    "  \n",
    "  # import training data\n",
    "  Xbuffer = import_images(train_path + 'images/', num_train_images)\n",
    "  Xtrain_rgb = np.array(Xbuffer[0:num_train_images], dtype=float) / 255\n",
    "  #Xtrain_rgb = np.load(train_path + 'trainArray.npy')\n",
    "  print('training data imported')\n",
    "\n",
    "  # import test data\n",
    "  Xbuffer = import_images(test_path + 'images/', num_test_images)\n",
    "  Xtest_rgb = np.array(Xbuffer[0:num_test_images], dtype=float) / 255\n",
    "\n",
    "# import data from drive (only for illustration)\n",
    "elif(read_mode==1):\n",
    "  Xbuffer = import_images(valid_path + 'images/', 4)\n",
    "  Xvalid_rgb = np.array(Xbuffer, dtype=float) / 255 \n",
    "  Xbuffer = import_images(train_path + 'images/', 4)\n",
    "  Xtrain_rgb = np.array(Xbuffer, dtype=float) / 255\n",
    "  Xbuffer = import_images(test_path + 'images/', 4)\n",
    "  Xtest_rgb = np.array(Xbuffer, dtype=float) / 255\n",
    "\n",
    "# plot 4 examples\n",
    "plotImages(Xtrain_rgb, 4)\n",
    "#plotImages(Xvalid_rgb, 4)\n",
    "#plotImages(Xtest_rgb, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 7362,
     "status": "ok",
     "timestamp": 1604868579627,
     "user": {
      "displayName": "A. Irgendwie",
      "photoUrl": "",
      "userId": "06901651170485627471"
     },
     "user_tz": -60
    },
    "id": "9fAMpW2OoBxS"
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# load weights of the external model (InceptionResNetV2)\n",
    "##############################################################\n",
    "modelInceptionResNet = InceptionResNetV2(weights=None, include_top=True)\n",
    "modelInceptionResNet.load_weights(working_path + '/extmodel/' + 'modelInceptionResNet.h5')\n",
    "#modelInceptionResNet.summary()\n",
    "\n",
    "# !!! download pretrained InceptionResNetV2 model:\n",
    "''' load and save InceptionResNet-model (first load)\n",
    "modelInceptionResNet = InceptionResNetV2(weights='imagenet', include_top=True)\n",
    "modelInceptionResNet.summary()\n",
    "save_model = modelInceptionResNet.to_json()\n",
    "with open(working_path + '/extmodel/' + 'modelInceptionResNet.json', \"w\") as json_file:\n",
    "  json_file.write(save_model)\n",
    "modelInceptionResNet.save_weights(working_path + '/extmodel/' + 'modelInceptionResNet.h5')\n",
    "'''\n",
    "\n",
    "# define and compile the full model\n",
    "modelEncDecIResNet = get_modelEncDecIResNet()\n",
    "modelEncDecIResNet.compile(optimizer=Adam(learning_rate=var_learning_rate),loss='mse',metrics=['mean_absolute_error',metric_psnr])\n",
    "#modelEncDecIResNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CvistZ9KiCeR",
    "outputId": "61b3c6ff-a737-4c1f-85f5-dd51f59814d9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data from drive\n",
      "Found 1 images belonging to 1 classes.\n",
      "Found 1 images belonging to 1 classes.\n",
      "Found 1 images belonging to 1 classes.\n",
      "start training\n",
      " For training batch 0, loss is 0.0097158.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - mean_absolute_error: 0.0672 - metric_psnr: 20.1252 For validation batch 0, loss is 0.0147897.\n",
      "\n",
      "Epoch 00001: saving model to C:\\Users\\d91482\\Desktop\\code\\finalVersion\\content\\RecolorizationEncDecIResNet/output/saved_model\\modelEncDecIResNet001.h5\n",
      "The average loss for epoch 0 is 0.0097158 and mean absolute error is 0.0671765.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0097 - mean_absolute_error: 0.0672 - metric_psnr: 20.1252 - val_loss: 0.0148 - val_mean_absolute_error: 0.1140 - val_metric_psnr: 18.3004 - lr: 1.0000e-04\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# generate batches and execute training\n",
    "##############################################################\n",
    "\n",
    "#DataGenerator = ImageDataGenerator(shear_range=0.1, zoom_range=0.1, rotation_range=10, horizontal_flip=True)\n",
    "DataGenerator = ImageDataGenerator(rescale=1./255)\n",
    "if(read_mode==0):\n",
    "  print('read data from array')\n",
    "  train_batches = DataGenerator.flow(Xtrain_rgb, batch_size=var_batch_size)\n",
    "  valid_batches = DataGenerator.flow(Xvalid_rgb, batch_size=var_batch_size)\n",
    "  test_batches = DataGenerator.flow(Xtest_rgb, batch_size=var_batch_size, shuffle=False)\n",
    "elif(read_mode==1):\n",
    "  print('read data from drive')\n",
    "  train_batches = DataGenerator.flow_from_directory(directory=train_path, batch_size=var_batch_size)\n",
    "  valid_batches = DataGenerator.flow_from_directory(directory=valid_path, batch_size=var_batch_size)\n",
    "  test_batches = DataGenerator.flow_from_directory(directory=test_path, batch_size=var_batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# checkpoints: save model weights after each epoch, save logs from tensorboard, save loss and metrics\n",
    "checkpoint = [ModelCheckpoint(output_path + 'saved_model/' + 'modelEncDecIResNet{epoch:03d}.h5', \n",
    "                            monitor='loss', verbose=1, save_best_only=False, mode='auto', save_freq='epoch'),\n",
    "              #TensorBoard(logs_path, update_freq='batch', write_graph=False, write_images=False),\n",
    "              CustomTensorBoard(logs_path, update_freq='batch', write_graph=False, write_images=False),\n",
    "              LossAndErrorPrintingCallback(),\n",
    "              #CSVLogger(output_path + 'log.csv', append = True, separator=';'),\n",
    "              ReduceLROnPlateau(monitor='loss', factor=0.5, verbose=1, patience=10, min_lr=0.000001),\n",
    "              ]\n",
    "\n",
    "# run model for training\n",
    "if run_mode == 0:\n",
    "  print('start training')\n",
    "  history_callback = modelEncDecIResNet.fit(batch_generator(var_batch_size, train_batches, modelInceptionResNet), \n",
    "                         epochs=var_epochs, \n",
    "                         steps_per_epoch=var_steps_per_epoch, \n",
    "                         validation_data = batch_generator(var_batch_size,valid_batches,modelInceptionResNet),\n",
    "                         validation_steps=var_steps_validation, \n",
    "                         verbose=var_verbose,\n",
    "                         callbacks=[checkpoint]\n",
    "                         )\n",
    "# proceed with training\n",
    "elif run_mode == 1:\n",
    "  print('load saved model, proceed with training')\n",
    "  modelEncDecIResNet.load_weights(output_path + 'saved_model/' + model_to_proceed)\n",
    "  history_callback = modelEncDecIResNet.fit(batch_generator(var_batch_size, train_batches, modelInceptionResNet), \n",
    "                         epochs=var_epochs, \n",
    "                         steps_per_epoch=var_steps_per_epoch, \n",
    "                         validation_data = batch_generator(var_batch_size,valid_batches,modelInceptionResNet),\n",
    "                         validation_steps=var_steps_validation, \n",
    "                         verbose=var_verbose, \n",
    "                         callbacks=[checkpoint],\n",
    "                         initial_epoch = var_initial_epoch\n",
    "                         )\n",
    "# model inference\n",
    "else:\n",
    "  print('load saved model, prepaired for inference')\n",
    "  modelEncDecIResNet.load_weights(output_path + 'saved_model/' + model_to_proceed)\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# save model and model weights, manually\n",
    "##############################################################\n",
    "'''\n",
    "if run_mode == 0 or run_mode == 1:\n",
    "  print('save model weigths')\n",
    "  save_model = modelEncDecIResNet.to_json()\n",
    "  with open(output_path + '/saved_model/' + 'modelEncDecIResNet.json', \"w\") as json_file:\n",
    "    json_file.write(save_model)\n",
    "  modelEncDecIResNet.save_weights(output_path + 'saved_model/' + 'modelEncDecIResNet.h5')\n",
    "'''\n",
    "##############################################################\n",
    "# compute loss on the validation set, manually\n",
    "##############################################################\n",
    "'''[Xvalid_lab,embed], Yvalid_lab = evaluate_input(Xvalid_rgb, modelInceptionResNet)\n",
    "print(modelEncDecIResNet.evaluate([Xvalid_lab,embed], Yvalid_lab, batch_size=var_batch_size))\n",
    "'''\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "c_Nq2fwos0jT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test images plotted\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# colorize images from test set\n",
    "#############################################################\n",
    "Xtest_rgb = []\n",
    "Xbuffer = import_images(test_path + 'images/', num_test_images)\n",
    "Xtest_rgb = np.array(Xbuffer, dtype=float) / 255\n",
    "\n",
    "[Xtest_lab,embed], Ytest_lab = evaluate_input(Xtest_rgb, modelInceptionResNet)\n",
    "Xpred_lab = modelEncDecIResNet.predict([Xtest_lab, embed])\n",
    "Xpred_lab =  Xpred_lab * 128\n",
    "\n",
    "for i in range(len(Xpred_lab)):\n",
    "    bufferImage = np.zeros((256, 256, 3))\n",
    "    bufferImage[:,:,0] = Xtest_lab[i][:,:,0]\n",
    "    bufferImage[:,:,1:] = Xpred_lab[i]\n",
    "    imsave(output_path+'results/'+str(i)+\".png\", img_as_ubyte(lab2rgb(bufferImage)))\n",
    "\n",
    "print('test images plotted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cNSlKgAhuFGX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!tensorboard dev upload --logdir ./logs     --name \"experiment: movie posters\"     --description \"training results \"     --one_shot'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################\n",
    "# initialize tensorboard session\n",
    "##############################################################\n",
    "'''!tensorboard dev upload --logdir ./logs \\\n",
    "    --name \"experiment: movie posters\" \\\n",
    "    --description \"training results \" \\\n",
    "    --one_shot'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8KaeyeU7RUBh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!tensorboard dev delete --experiment_id #'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete tensorboard session\n",
    "'''!tensorboard dev delete --experiment_id #'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7JRPTABLv2tH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"!zip -r RecolorizationEncDecIResNetResult.zip '/content/RecolorizationEncDecIResNet/'\\n!cp RecolorizationEncDecIResNetResult.zip /content/drive/My\\\\ Drive/\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################\n",
    "# only for Colab\n",
    "##############################################################\n",
    "'''!zip -r RecolorizationEncDecIResNetResult.zip '/content/RecolorizationEncDecIResNet/'\n",
    "!cp RecolorizationEncDecIResNetResult.zip /content/drive/My\\ Drive/'''"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO0dFg+/DQ+plGDWPraJMfV",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "11S9Hm4amlbhK282TSVx58539OLBcLw6a",
   "name": "RecolorizationEncDecIResNet_VerDrive_Version1.0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
